{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c011f5d-1962-4ec4-baae-41f4146d7506",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df072cec-6ec7-4fdc-a7b1-b8b4205709c6",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a485b28b-690e-44b6-9059-069580adb015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: amplify in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (0.0.0)\n",
      "Requirement already satisfied: textualheatmap in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (1.2.0)\n",
      "Requirement already satisfied: captum in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (0.7.0)\n",
      "Requirement already satisfied: torch==2.2.* in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from amplify) (2.2.0)\n",
      "Requirement already satisfied: accelerate==0.27.* in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from amplify) (0.27.2)\n",
      "Requirement already satisfied: deepspeed==0.13.* in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from amplify) (0.13.5)\n",
      "Requirement already satisfied: xformers==0.0.24.* in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from amplify) (0.0.24)\n",
      "Requirement already satisfied: transformers==4.38.* in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from amplify) (4.38.2)\n",
      "Requirement already satisfied: datasets==2.17.* in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from amplify) (2.17.1)\n",
      "Requirement already satisfied: wandb==0.16.* in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from amplify) (0.16.6)\n",
      "Requirement already satisfied: hydra-core==1.3.* in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from amplify) (1.3.2)\n",
      "Requirement already satisfied: numpy==1.26.* in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from amplify) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from accelerate==0.27.*->amplify) (24.1)\n",
      "Requirement already satisfied: psutil in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from accelerate==0.27.*->amplify) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from accelerate==0.27.*->amplify) (6.0.2)\n",
      "Requirement already satisfied: huggingface-hub in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from accelerate==0.27.*->amplify) (0.25.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from accelerate==0.27.*->amplify) (0.4.5)\n",
      "Requirement already satisfied: filelock in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from datasets==2.17.*->amplify) (3.16.1)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from datasets==2.17.*->amplify) (17.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from datasets==2.17.*->amplify) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from datasets==2.17.*->amplify) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from datasets==2.17.*->amplify) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from datasets==2.17.*->amplify) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from datasets==2.17.*->amplify) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from datasets==2.17.*->amplify) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from datasets==2.17.*->amplify) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.17.*->amplify) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from datasets==2.17.*->amplify) (3.10.8)\n",
      "Requirement already satisfied: hjson in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from deepspeed==0.13.*->amplify) (3.1.0)\n",
      "Requirement already satisfied: ninja in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from deepspeed==0.13.*->amplify) (1.11.1.1)\n",
      "Requirement already satisfied: py-cpuinfo in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from deepspeed==0.13.*->amplify) (9.0.0)\n",
      "Requirement already satisfied: pydantic in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from deepspeed==0.13.*->amplify) (2.9.2)\n",
      "Requirement already satisfied: pynvml in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from deepspeed==0.13.*->amplify) (11.5.3)\n",
      "Requirement already satisfied: omegaconf<2.4,>=2.2 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from hydra-core==1.3.*->amplify) (2.3.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from hydra-core==1.3.*->amplify) (4.9.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from torch==2.2.*->amplify) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from torch==2.2.*->amplify) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from torch==2.2.*->amplify) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from torch==2.2.*->amplify) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from torch==2.2.*->amplify) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from torch==2.2.*->amplify) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from torch==2.2.*->amplify) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from torch==2.2.*->amplify) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from torch==2.2.*->amplify) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from torch==2.2.*->amplify) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from torch==2.2.*->amplify) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from torch==2.2.*->amplify) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from torch==2.2.*->amplify) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from torch==2.2.*->amplify) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from torch==2.2.*->amplify) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from torch==2.2.*->amplify) (2.2.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from transformers==4.38.*->amplify) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from transformers==4.38.*->amplify) (0.15.2)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from wandb==0.16.*->amplify) (8.1.7)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from wandb==0.16.*->amplify) (3.1.43)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from wandb==0.16.*->amplify) (2.14.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from wandb==0.16.*->amplify) (0.4.0)\n",
      "Requirement already satisfied: setproctitle in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from wandb==0.16.*->amplify) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from wandb==0.16.*->amplify) (74.0.0)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from wandb==0.16.*->amplify) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from wandb==0.16.*->amplify) (4.25.5)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.*->amplify) (12.6.68)\n",
      "Requirement already satisfied: ipython in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from textualheatmap) (8.27.0)\n",
      "Requirement already satisfied: matplotlib in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from captum) (3.9.2)\n",
      "Requirement already satisfied: decorator in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from ipython->textualheatmap) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from ipython->textualheatmap) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from ipython->textualheatmap) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from ipython->textualheatmap) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from ipython->textualheatmap) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from ipython->textualheatmap) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from ipython->textualheatmap) (5.14.3)\n",
      "Requirement already satisfied: exceptiongroup in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from ipython->textualheatmap) (1.2.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from ipython->textualheatmap) (4.9.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from matplotlib->captum) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from matplotlib->captum) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from matplotlib->captum) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from matplotlib->captum) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from matplotlib->captum) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from matplotlib->captum) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from matplotlib->captum) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.4.0 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb==0.16.*->amplify) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from aiohttp->datasets==2.17.*->amplify) (2.4.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from aiohttp->datasets==2.17.*->amplify) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from aiohttp->datasets==2.17.*->amplify) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from aiohttp->datasets==2.17.*->amplify) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from aiohttp->datasets==2.17.*->amplify) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from aiohttp->datasets==2.17.*->amplify) (1.13.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from aiohttp->datasets==2.17.*->amplify) (4.0.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb==0.16.*->amplify) (4.0.11)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from jedi>=0.16->ipython->textualheatmap) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from pexpect>4.3->ipython->textualheatmap) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython->textualheatmap) (0.2.13)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.17.*->amplify) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.17.*->amplify) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.17.*->amplify) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.17.*->amplify) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from jinja2->torch==2.2.*->amplify) (2.1.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from pandas->datasets==2.17.*->amplify) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from pandas->datasets==2.17.*->amplify) (2024.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from pydantic->deepspeed==0.13.*->amplify) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from pydantic->deepspeed==0.13.*->amplify) (2.23.4)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from stack-data->ipython->textualheatmap) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from stack-data->ipython->textualheatmap) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from stack-data->ipython->textualheatmap) (0.2.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from sympy->torch==2.2.*->amplify) (1.3.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb==0.16.*->amplify) (5.0.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install amplify textualheatmap captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ed57d6e-dd50-4e4f-9017-19ba8e65fffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mila/j/jerry.huang/main_envs/amplify_env/bin/python\n",
      "Python 3.10.11\n"
     ]
    }
   ],
   "source": [
    "!which python\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77fdaddc-993c-472c-8813-fb6d75e2268f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Cython in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (3.0.11)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: textualheatmap in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (1.2.0)\n",
      "Requirement already satisfied: ipython in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from textualheatmap) (8.27.0)\n",
      "Requirement already satisfied: decorator in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from ipython->textualheatmap) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from ipython->textualheatmap) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from ipython->textualheatmap) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from ipython->textualheatmap) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from ipython->textualheatmap) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from ipython->textualheatmap) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from ipython->textualheatmap) (5.14.3)\n",
      "Requirement already satisfied: exceptiongroup in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from ipython->textualheatmap) (1.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from ipython->textualheatmap) (4.12.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from ipython->textualheatmap) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from jedi>=0.16->ipython->textualheatmap) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from pexpect>4.3->ipython->textualheatmap) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython->textualheatmap) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from stack-data->ipython->textualheatmap) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from stack-data->ipython->textualheatmap) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from stack-data->ipython->textualheatmap) (0.2.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython->textualheatmap) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install Cython\n",
    "!pip install textualheatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8bd9e63-4c58-4606-816c-34c5ddb95a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-25 14:11:01,247] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from captum.attr import configure_interpretable_embedding_layer\n",
    "from utils import load_pickle_dataset, load_from_hf, load_from_mila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47e154ce-8b5f-4147-bc7b-51764d615404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "source = \"mila\"\n",
    "model_name = \"AMPLIFY350M\"\n",
    "model_path = \"/network/projects/drugdiscovery/AMPLIFY/checkpoints/AMPLIFY_350M/pytorch_model.pt\"\n",
    "tokenizer_path = None \n",
    "config_path = \"AMPLIFY_350_config.yaml\"\n",
    "device = \"cuda\"\n",
    "compile = False\n",
    "fp16 = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b413127-2c0e-4735-ac77-e01cd517b021",
   "metadata": {},
   "source": [
    "## Load Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf7a5a51-026d-49c4-8f1c-e0598de6e25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/j/jerry.huang/main_envs/amplify_env/lib/python3.10/site-packages/captum/attr/_models/base.py:191: UserWarning: In order to make embedding layers more interpretable they will be replaced with an interpretable embedding layer which wraps the original embedding layer and takes word embedding vectors as inputs of the forward function. This allows us to generate baselines for word embeddings and compute attributions for each embedding dimension. The original embedding layer must be set back by calling `remove_interpretable_embedding_layer` function after model interpretation is finished. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AMPLIFY(\n",
       "  (encoder): InterpretableEmbeddingBase(\n",
       "    (embedding): Embedding(27, 960, padding_idx=0)\n",
       "  )\n",
       "  (transformer_encoder): ModuleList(\n",
       "    (0-31): 32 x EncoderBlock(\n",
       "      (q): Linear(in_features=960, out_features=960, bias=False)\n",
       "      (k): Linear(in_features=960, out_features=960, bias=False)\n",
       "      (v): Linear(in_features=960, out_features=960, bias=False)\n",
       "      (wo): Linear(in_features=960, out_features=960, bias=False)\n",
       "      (resid_dropout): Dropout(p=0, inplace=False)\n",
       "      (ffn): SwiGLU(\n",
       "        (w12): Linear(in_features=960, out_features=5120, bias=False)\n",
       "        (w3): Linear(in_features=2560, out_features=960, bias=False)\n",
       "      )\n",
       "      (attention_norm): RMSNorm()\n",
       "      (ffn_norm): RMSNorm()\n",
       "      (ffn_dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (layer_norm_2): RMSNorm()\n",
       "  (decoder): Linear(in_features=960, out_features=27, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get model and tokenizer\n",
    "if source == \"hf\":\n",
    "    model, tokenizer = load_from_hf(model_path, tokenizer_path, fp16=fp16)\n",
    "    interpretable_embedding = configure_interpretable_embedding_layer(model, \"esm.embeddings.word_embeddings\")\n",
    "    bos_id, mask_id, eos_id = tokenizer.cls_token_id, tokenizer.mask_token_id, tokenizer.eos_token_id\n",
    "elif source == \"mila\":\n",
    "    model, tokenizer = load_from_mila(model_path, config_path)\n",
    "    interpretable_embedding = configure_interpretable_embedding_layer(model, \"encoder\")\n",
    "    bos_id, mask_id, eos_id = tokenizer.bos_token_id, tokenizer.mask_token_id, tokenizer.eos_token_id\n",
    "else:\n",
    "    raise Exception(\"Only 'hf' and 'mila' sources are supported, not {source}.\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6de719d-fd4f-472a-866b-afd35080b7ba",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "8cf4c496-adc8-4fdd-925a-b4e6d09523f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">A6I415|A6I415_RAT MFTVMTRQPCEQAGFRALSRTPAIVTLVVLLVSIVVLVTLTLIQIHHPQVLSPGLKYGIVLDAGSSRTTVYVYQWPAEKENNTGVVSQTFRCSVKGSGISSYENNPQDAPKAFEDCMLKVKEQVPKHLHESTRVYLGATAGMRLLRLQNETAAHEVLESIQSYFKSQPFDFRGAQIISGQEEGVYGWITANYIMGNFLEKNLWHMWVHPHGVDTTGALDLGGASTQISFVSEEKMEPNASDTVQVSLYGYTYTLYTHSFQCYGRNEAEKKFLAMLLQSPSTDANISNPCYPHGYSTTFTMGHVFGSLCTEKQRPKSYNPSDTITFTGTGDPQLCREKVASVFDFSACQEQDACSFDGIYQPKVQGPFVAFAGFYYTASALNLSGSFSLTSFNDSSWDFCRHTWSELPSLLPRFDETYARSYCFSAHYIYHLLINGYKFTEATWPQIRFEKEVGNSSIAWSLGYMLSLTNQIPAGSPLIQLPIQPPVFMGVLAFFTAIALLCLAFLFYLCSAFRTKERSENAFDQAVDSD\n",
      ">Q9NVV2|CS073_HUMAN MRLKVGFQGGGCFRKDALCLEGGVSARWARAPHSAPLRPPRELHAAPPPATPTQTVVRPAGFPRRTRLMVRSAPPTQRPPTGSGCVSGLWRKGLGLRPQTLLRVGSVVLSSAPALRPRLGPCLRPPPSD\n",
      ">O00628|PEX7_HUMAN MSAVCGGAARMLRTPGRHGYAAEFSPYLPGRLACATAQHYGIAGCGTLLILDPDEAGLRLFRSFDWNDGLFDVTWSENNEHVLITCSGDGSLQLWDTAKAAGPLQVYKEHAQEVYSVDWSQTRGEQLVVSGSWDQTVKLWDPTVGKSLCTFRGHESIIYSTIWSPHIPGCFASASGDQTLRIWDVKAAGVRIVIPAHQAEILSCDWCKYNENLLVTGAVDCSLRGWDLRNVRQPVFELLGHTYAIRRVKFSPFHASVLASCSYDFTVRFWNFSKPDSLLETVEHHTEFTCGLDFSLQSPTQVADCSWDETIKIYDPACLTIPA\n",
      ">A0A8M9P7W8|A0A8M9P7W8_DANRE MKLPSVASLLIRVYRTTGPVSHIQRIRHGAVLNKNYSSVSAVKNCTALLYRNHGEPSQVVQLESLDLPQVGAECVLVKMLAAPINPSDLNMLQGTYAILPELPAVGGNEGVAQVMEVGDKVKTLKVGDWVIPKDAGIGTWRTAAVLKADDLVTLPKDIPVLSAATLGVNPCTAYRMLTDFEELKAGRQCS\n",
      ">A0A5G2R2Q0|A0A5G2R2Q0_PIG MYVDSLYIQHTILCKLIALYWEEKTDSKKVEENIKTDEPSSEESDLEIDNEGVIEPDTDAPQEMGDENVEITEEMMDQANDKKVAAIDALNNGELQKAIDLFTDAIKLNPRLAILYAKRASVFIKLQKPNAAIRDCDRAIEINPDSAQPYKWRGKAHRLLGHWEEAAHDLALACKLDYDEDASAMLKEVQPRAQKIAEHRRKYERKREEREIKERIERVKKAREEHERAQREEEARRQSGAQYGSFPGGFPGGMPGNFPGGMPGMGGSMPGMAGMPGLNEILSDPEVLAAMQDPEVMVAFQDVAQNPANMSKYQSNPKVMNLISKLSAKFGGQA\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from utils import load_csv_dataset\n",
    "\n",
    "# Dataset\n",
    "n_proteins = 1_000_000\n",
    "\n",
    "dataset = \"UniProt\"\n",
    "\n",
    "if dataset == \"CASP\":\n",
    "    data_name = \"CASP14\"\n",
    "    data_path = \"casp14.pickle\"\n",
    "    max_length = 2048 # AMPLIFY was trained with a context length of 512\n",
    "\n",
    "    # Load\n",
    "    output_file = \"../outputs/AMPLIFY_Attribution_MaskedKL.csv\"\n",
    "\n",
    "    # Load dataset\n",
    "    labels, proteins, dist_matrices = load_pickle_dataset(data_path, n_proteins, max_length)\n",
    "\n",
    "    full_dataset = list(zip(labels, proteins))\n",
    "    \n",
    "    for (label, protein) in itertools.islice(full_dataset, 0, 5):\n",
    "        print(label, protein)\n",
    "    \n",
    "else:\n",
    "    # Dataset\n",
    "    data_name = \"UniProt\"\n",
    "    data_path = \"uniprot_dev.csv\"\n",
    "    \n",
    "    # Log\n",
    "    output_file = \"../outputs/AMPLIFY_UniProt_MaskedKL.csv\"\n",
    "    \n",
    "    # Prepare the dataset\n",
    "    full_dataset = load_csv_dataset(data_path, n_proteins)\n",
    "    \n",
    "    # Generator that, for each protein, tokenize, mask each residue, and batch\n",
    "    # def batch_tokenize_mask(dataset, tokenizer, batch_size):\n",
    "    #     for label, protein in dataset:\n",
    "    #         x = torch.as_tensor(tokenizer.encode(protein, max_length=512, truncation=True))\n",
    "    #         x = x.repeat(x.size(0), 1)\n",
    "    #         y = torch.where(torch.eye(x.size(0), dtype=torch.bool), x, -100)\n",
    "    #         x = torch.where(torch.eye(x.size(0), dtype=torch.bool), tokenizer.mask_token_id, x)\n",
    "    #         for _x, _y in zip(torch.split(x, batch_size, 0), torch.split(y, batch_size, 0)):\n",
    "    #             yield (label, _x, _y)\n",
    "    \n",
    "    for (label, protein) in itertools.islice(full_dataset, 0, 5):\n",
    "        print(label, protein)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "9fd3464b-68b0-491e-af1c-b560083378b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(full_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b6ed92-ebe6-43e6-a63f-f29f9fa26445",
   "metadata": {},
   "source": [
    "# Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88b5c07-620b-4bbb-bb4a-ca933c515c99",
   "metadata": {},
   "source": [
    "## Test with one protein first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f8d599cb-790e-43db-931a-c9ed53bbe59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2803, 960])\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[176], line 78\u001b[0m\n\u001b[1;32m     76\u001b[0m reference_embeddings \u001b[38;5;241m=\u001b[39m interpretable_embedding\u001b[38;5;241m.\u001b[39mindices_to_embeddings(reference_input)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mprint\u001b[39m(reference_embeddings\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 78\u001b[0m reference_output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreference_embeddings\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m     80\u001b[0m mask_indices \u001b[38;5;241m=\u001b[39m masked_ids\u001b[38;5;241m.\u001b[39mnonzero()\n\u001b[1;32m     82\u001b[0m test_input \u001b[38;5;241m=\u001b[39m reference_input\u001b[38;5;241m.\u001b[39mrepeat(mask_indices\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/main_envs/amplify_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/main_envs/amplify_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/main_envs/amplify_env/lib/python3.10/site-packages/amplify/model/amplify.py:250\u001b[0m, in \u001b[0;36mAMPLIFY.forward\u001b[0;34m(self, src, pad_mask, output_hidden_states, output_attentions)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# Transformer encoder\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer_encoder:\n\u001b[0;32m--> 250\u001b[0m     x, attn \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreqs_cis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[1;32m    252\u001b[0m         hidden_states\u001b[38;5;241m.\u001b[39mappend(x)\n",
      "File \u001b[0;32m~/main_envs/amplify_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/main_envs/amplify_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/main_envs/amplify_env/lib/python3.10/site-packages/amplify/model/amplify.py:131\u001b[0m, in \u001b[0;36mEncoderBlock.forward\u001b[0;34m(self, x, pad_mask, freqs_cis, output_attentions)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor, pad_mask: torch\u001b[38;5;241m.\u001b[39mTensor, freqs_cis: torch\u001b[38;5;241m.\u001b[39mTensor, output_attentions: \u001b[38;5;28mbool\u001b[39m):\n\u001b[0;32m--> 131\u001b[0m     attn, contact \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_att_block\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreqs_cis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m attn\n\u001b[1;32m    133\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffn_norm(x))\n",
      "File \u001b[0;32m~/main_envs/amplify_env/lib/python3.10/site-packages/amplify/model/amplify.py:144\u001b[0m, in \u001b[0;36mEncoderBlock._att_block\u001b[0;34m(self, x, pad_mask, freqs_cis, output_attentions)\u001b[0m\n\u001b[1;32m    142\u001b[0m xk \u001b[38;5;241m=\u001b[39m xk\u001b[38;5;241m.\u001b[39mview(batch_size, seq_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_attention_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_head)\n\u001b[1;32m    143\u001b[0m xv \u001b[38;5;241m=\u001b[39m xv\u001b[38;5;241m.\u001b[39mview(batch_size, seq_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_attention_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_head)\n\u001b[0;32m--> 144\u001b[0m xq, xk \u001b[38;5;241m=\u001b[39m \u001b[43mapply_rotary_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreqs_cis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m attn \u001b[38;5;241m=\u001b[39m memory_efficient_attention(\n\u001b[1;32m    147\u001b[0m     query\u001b[38;5;241m=\u001b[39mxq,\n\u001b[1;32m    148\u001b[0m     key\u001b[38;5;241m=\u001b[39mxk,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    151\u001b[0m     p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdropout_prob \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    152\u001b[0m )\n\u001b[1;32m    154\u001b[0m _attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/main_envs/amplify_env/lib/python3.10/site-packages/amplify/model/rotary.py:77\u001b[0m, in \u001b[0;36mapply_rotary_emb\u001b[0;34m(xq, xk, freqs_cis)\u001b[0m\n\u001b[1;32m     75\u001b[0m xq_ \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mview_as_complex(xq\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m*\u001b[39mxq\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m     76\u001b[0m xk_ \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mview_as_complex(xk\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m*\u001b[39mxk\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m---> 77\u001b[0m freqs_cis \u001b[38;5;241m=\u001b[39m \u001b[43mreshape_for_broadcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfreqs_cis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxq_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m xq_out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mview_as_real(xq_ \u001b[38;5;241m*\u001b[39m freqs_cis)\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     79\u001b[0m xk_out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mview_as_real(xk_ \u001b[38;5;241m*\u001b[39m freqs_cis)\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[0;32m~/main_envs/amplify_env/lib/python3.10/site-packages/amplify/model/rotary.py:49\u001b[0m, in \u001b[0;36mreshape_for_broadcast\u001b[0;34m(freqs_cis, x)\u001b[0m\n\u001b[1;32m     47\u001b[0m ndim \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mndim\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m ndim\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m freqs_cis\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     50\u001b[0m shape \u001b[38;5;241m=\u001b[39m [d \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m i \u001b[38;5;241m==\u001b[39m ndim \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)]\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m freqs_cis\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m*\u001b[39mshape)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# TF32 and FP16\n",
    "\n",
    "span_probability = None\n",
    "span_max = 1\n",
    "mask_probability = 0.15\n",
    "\n",
    "# span_probability = 0.15\n",
    "# span_max = 10\n",
    "# mask_probability = 0.15\n",
    "\n",
    "exclude_special_tokens_replacement = False\n",
    "replacement_ids = torch.ones((len(tokenizer)))\n",
    "if exclude_special_tokens_replacement:\n",
    "    for i in tokenizer.special_token_ids:\n",
    "        replacement_ids[i] = 0\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "num_passes = 1\n",
    "\n",
    "with torch.autocast(device_type=device, dtype=torch.float16, enabled=fp16):\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    \n",
    "    if dataset == \"CASP\":\n",
    "        label, protein = labels[0], proteins[0]\n",
    "    else:\n",
    "        label, protein = full_dataset[79][0], full_dataset[79][1]\n",
    "       \n",
    "    # Tokenize the protein and decode to get the special tokens\n",
    "    x = torch.as_tensor(tokenizer.encode(protein)).to(torch.long)\n",
    "    protein = tokenizer.decode(x, skip_special_tokens=False).split()\n",
    "\n",
    "    for _ in range(num_passes):\n",
    "    \n",
    "        masked_ids = torch.full(size=(len(protein),), fill_value=False, dtype=torch.bool)\n",
    "        \n",
    "        # Compute the padding, <bos> and <eos> masks\n",
    "        pad_mask = x == tokenizer.pad_token_id\n",
    "        bos_mask = x == tokenizer.bos_token_id\n",
    "        eos_mask = x == tokenizer.eos_token_id\n",
    "    \n",
    "        # MLM\n",
    "        if span_probability is None or span_max is None or span_probability == 0 or span_max == 1:\n",
    "            probability_matrix = torch.full(x.shape, mask_probability)\n",
    "            probability_matrix.masked_fill_(pad_mask | bos_mask | eos_mask, value=0.0)\n",
    "            masked_ids = torch.bernoulli(probability_matrix).bool()\n",
    "    \n",
    "        # Span masking\n",
    "        else:\n",
    "            uniform_dist = torch.distributions.uniform.Uniform(0, len(protein))\n",
    "            geometric_dist = torch.distributions.geometric.Geometric(span_probability)\n",
    "            while torch.sum(masked_ids) / len(protein) < mask_probability:\n",
    "                span_start = int(uniform_dist.sample().item())\n",
    "                span_length = int(min(geometric_dist.sample().item(), span_max - 1, len(protein) - span_start))\n",
    "                masked_ids[span_start : span_start + span_length + 1] = True\n",
    "                # Unmask the padding, <bos> and <eos> tokens (note that padding should not be necessary)\n",
    "                masked_ids = masked_ids & ~pad_mask & ~bos_mask & ~eos_mask\n",
    "    \n",
    "        y = x.clone()\n",
    "        \n",
    "        # 80% of the time, the masked input tokens are replaced with <MASK>\n",
    "        replaced_ids = torch.bernoulli(torch.full(y.shape, 0.8)).bool() & masked_ids\n",
    "        x[replaced_ids] = tokenizer.mask_token_id\n",
    "    \n",
    "        # 10% of the time, the masked input tokens are replaced with a random word\n",
    "        random_ids = torch.bernoulli(torch.full(y.shape, 0.5)).bool() & masked_ids & ~replaced_ids\n",
    "        random_words = torch.multinomial(replacement_ids, torch.numel(x), replacement=True).view(x.size())\n",
    "        x[random_ids] = random_words[random_ids]\n",
    "    \n",
    "        reference_input = x.unsqueeze(0)\n",
    "        reference_input = reference_input.to(device)\n",
    "        reference_embeddings = interpretable_embedding.indices_to_embeddings(reference_input)\n",
    "        print(reference_embeddings.shape)\n",
    "        reference_output = model(reference_embeddings).logits\n",
    "        \n",
    "        mask_indices = masked_ids.nonzero()\n",
    "        \n",
    "        test_input = reference_input.repeat(mask_indices.size(0), 1)\n",
    "        for index, value in enumerate(mask_indices):\n",
    "            test_input[index, value] = y[value]\n",
    "    \n",
    "        assert test_input[0, mask_indices[0][0]] == y[mask_indices[0][0]], \"Masking isn't correct!\"\n",
    "    \n",
    "        test_embeddings = interpretable_embedding.indices_to_embeddings(test_input)\n",
    "        test_output = model(test_embeddings).logits\n",
    "    \n",
    "        mask_indices = mask_indices.squeeze()\n",
    "        \n",
    "        pairs = itertools.permutations(torch.arange(len(mask_indices)).detach().tolist(), 2)\n",
    "\n",
    "        tot_distance = len(protein)\n",
    "    \n",
    "        for (modified_index, target_index) in pairs:\n",
    "\n",
    "            distance = abs(mask_indices[target_index] - mask_indices[modified_index]).item()\n",
    "            \n",
    "            original_logits = reference_output[0][mask_indices[target_index]]\n",
    "            new_logits = test_output[modified_index][mask_indices[target_index]]\n",
    "    \n",
    "            absolute_difference = torch.mean(torch.abs(original_logits - new_logits)).detach().item()\n",
    "    \n",
    "            log_softmax_reference = F.log_softmax(original_logits, dim=0)\n",
    "            softmax_targets = F.softmax(new_logits, dim=0)\n",
    "    \n",
    "            kl_div = F.kl_div(log_softmax_reference, softmax_targets, reduction=\"none\").mean().detach().item()\n",
    "    \n",
    "            print(label, model_name, mask_indices.tolist(), mask_indices[modified_index].item(), mask_indices[target_index].item(), absolute_difference, kl_div, distance, tot_distance)\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "d5a97251-1b7a-48eb-898e-ca51316e7173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import traceback \n",
    "\n",
    "def get_dataset(dataset, num_passes: int = 1):\n",
    "    for i in range(num_passes):\n",
    "        for sample in dataset:\n",
    "            yield sample\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_attributions(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    proteins,\n",
    "    device: torch.device,\n",
    "    save_file: Path,\n",
    "    chunk_size: int = 128,\n",
    "    mask_probability: float = 0.15,\n",
    "    span_probability: float = None,\n",
    "    span_max: int = 1,\n",
    "    masked_only: bool = True,\n",
    "    exclude_special_tokens_replacement: bool = False,\n",
    "    fp16: bool = True,\n",
    "    max_length: int = None\n",
    "):  \n",
    "    # TF32 and FP16\n",
    "    \n",
    "    replacement_ids = torch.ones((len(tokenizer)))\n",
    "    if exclude_special_tokens_replacement:\n",
    "        for i in tokenizer.special_token_ids:\n",
    "            replacement_ids[i] = 0\n",
    "\n",
    "    # file = open(save_file, 'wb')\n",
    "    # try:\n",
    "    \n",
    "    with open(save_file, 'wb') as file:\n",
    "        with torch.autocast(device_type=device, dtype=torch.bfloat16, enabled=fp16):\n",
    "            torch.backends.cuda.matmul.allow_tf32 = True\n",
    "            torch.backends.cudnn.allow_tf32 = True\n",
    "            \n",
    "            for i, (label, protein) in enumerate(proteins):\n",
    "               \n",
    "                # Tokenize the protein and decode to get the special tokens\n",
    "                x = torch.as_tensor(tokenizer.encode(protein)).to(torch.long)\n",
    "                protein = tokenizer.decode(x, skip_special_tokens=False).split()\n",
    "\n",
    "                if len(protein) > max_length:\n",
    "                    continue\n",
    "                \n",
    "                masked_ids = torch.full(size=(len(protein),), fill_value=False, dtype=torch.bool)\n",
    "                \n",
    "                # Compute the padding, <bos> and <eos> masks\n",
    "                pad_mask = x == tokenizer.pad_token_id\n",
    "                bos_mask = x == tokenizer.bos_token_id\n",
    "                eos_mask = x == tokenizer.eos_token_id\n",
    "            \n",
    "                # MLM\n",
    "                if span_probability is None or span_max is None or span_probability == 0 or span_max == 1:\n",
    "                    probability_matrix = torch.full(x.shape, mask_probability)\n",
    "                    probability_matrix.masked_fill_(pad_mask | bos_mask | eos_mask, value=0.0)\n",
    "                    masked_ids = torch.bernoulli(probability_matrix).bool()\n",
    "            \n",
    "                # Span masking\n",
    "                else:\n",
    "                    uniform_dist = torch.distributions.uniform.Uniform(0, len(protein))\n",
    "                    geometric_dist = torch.distributions.geometric.Geometric(span_probability)\n",
    "                    while torch.sum(masked_ids) / len(protein) < mask_probability:\n",
    "                        span_start = int(uniform_dist.sample().item())\n",
    "                        span_length = int(min(geometric_dist.sample().item(), span_max - 1, len(protein) - span_start))\n",
    "                        masked_ids[span_start : span_start + span_length + 1] = True\n",
    "                        # Unmask the padding, <bos> and <eos> tokens (note that padding should not be necessary)\n",
    "                        masked_ids = masked_ids & ~pad_mask & ~bos_mask & ~eos_mask\n",
    "            \n",
    "                y = x.clone()\n",
    "    \n",
    "                # Replace only with mask\n",
    "                if masked_only:\n",
    "                    x[masked_ids] = tokenizer.mask_token_id\n",
    "    \n",
    "                # Replace with both mask and random words\n",
    "                else:\n",
    "                    # 80% of the time, the masked input tokens are replaced with <MASK>\n",
    "                    replaced_ids = torch.bernoulli(torch.full(y.shape, 0.8)).bool() & masked_ids\n",
    "                    x[replaced_ids] = tokenizer.mask_token_id\n",
    "                \n",
    "                    # 10% of the time, the masked input tokens are replaced with a random word\n",
    "                    random_ids = torch.bernoulli(torch.full(y.shape, 0.5)).bool() & masked_ids & ~replaced_ids\n",
    "                    random_words = torch.multinomial(replacement_ids, torch.numel(x), replacement=True).view(x.size())\n",
    "                    x[random_ids] = random_words[random_ids]\n",
    "    \n",
    "                # Get reference output (relevant positions are replaced)\n",
    "                reference_input = x.unsqueeze(0)\n",
    "                reference_input = reference_input.to(device)\n",
    "                reference_embeddings = interpretable_embedding.indices_to_embeddings(reference_input)\n",
    "                reference_output = model(reference_embeddings).logits\n",
    "    \n",
    "                # Get masked outputs\n",
    "                mask_indices = masked_ids.nonzero()\n",
    "    \n",
    "                # Create test sequences (each sequence has a single mask value replaced with its real value)\n",
    "                test_input = reference_input.repeat(mask_indices.size(0), 1)\n",
    "                for index, value in enumerate(mask_indices):\n",
    "                    test_input[index, value] = y[value]\n",
    "    \n",
    "                # Assert that our replacement matches\n",
    "                assert test_input[0, mask_indices[0][0]] == y[mask_indices[0][0]], \"Masking isn't correct!\"\n",
    "    \n",
    "                # Create embeddings for the testing seqeunces and get the logits from a forward pass\n",
    "                test_embeddings = interpretable_embedding.indices_to_embeddings(test_input)\n",
    "                test_output = model(test_embeddings).logits\n",
    "    \n",
    "                # Compute attributions in terms of the KL divergence and the absolute change in logits\n",
    "                mask_indices = mask_indices.squeeze()\n",
    "\n",
    "                if mask_indices.shape[0] <= 2:\n",
    "                    print(f\"Skipped protein {label} with length {len(protein)}.\")\n",
    "                \n",
    "                pairs = itertools.permutations(torch.arange(mask_indices.shape[0]).detach().tolist(), 2)\n",
    "        \n",
    "                tot_distance = len(protein)\n",
    "    \n",
    "                pass_data = {\n",
    "                    'label': label,\n",
    "                    'model': model_name,\n",
    "                    'mask_indices': mask_indices.tolist(),\n",
    "                    'masked_index': [],\n",
    "                    'target_index': [],\n",
    "                    'absolute_difference': [], \n",
    "                    'kl_div': [], \n",
    "                    'distance': [], \n",
    "                    'tot_distance': tot_distance\n",
    "                }\n",
    "            \n",
    "                for (modified_index, target_index) in pairs:\n",
    "        \n",
    "                    distance = abs(mask_indices[target_index] - mask_indices[modified_index]).item()\n",
    "                    \n",
    "                    original_logits = reference_output[0][mask_indices[target_index]]\n",
    "                    new_logits = test_output[modified_index][mask_indices[target_index]]\n",
    "            \n",
    "                    absolute_difference = torch.mean(torch.abs(original_logits - new_logits)).detach().item()\n",
    "            \n",
    "                    log_softmax_reference = F.log_softmax(original_logits, dim=0)\n",
    "                    softmax_targets = F.softmax(new_logits, dim=0)\n",
    "            \n",
    "                    kl_div = F.kl_div(log_softmax_reference, softmax_targets, reduction=\"none\").mean().detach().item()\n",
    "    \n",
    "                    pass_data['masked_index'].append(modified_index)\n",
    "                    pass_data['target_index'].append(target_index)\n",
    "                    pass_data['absolute_difference'].append(absolute_difference)\n",
    "                    pass_data['kl_div'].append(kl_div)\n",
    "                    pass_data['distance'].append(distance)\n",
    "                    \n",
    "                pickle.dump(pass_data, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    # except:\n",
    "    #     file.close()\n",
    "    #     traceback.print_exc() \n",
    "    #     return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "026af327-4f1c-47a0-b7d9-f6a13c19d651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMPLIFY_350_config.yaml      feature_ablation.ipynb\ttest.pkl\n",
      "attribution.ipynb\t     masked_influence.ipynb\tuniprot_dev.csv\n",
      "casp14.pickle\t\t     projection_proteins.ipynb\tuniprot_dev.fasta\n",
      "compute_masked_influence.py  projection_residues.ipynb\tuniprot_dev.fasta.zip\n",
      "contact_prediction.ipynb     pseudo_ppl.ipynb\t\tuniprot.fasta\n",
      "efficiency.ipynb\t     __pycache__\t\tutils.py\n"
     ]
    }
   ],
   "source": [
    "! ls\n",
    "# ! rm -r test.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "0ffa2dfa-3b2c-4319-b8a0-a5b9bc84134c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">A6I415|A6I415_RAT MFTVMTRQPCEQAGFRALSRTPAIVTLVVLLVSIVVLVTLTLIQIHHPQVLSPGLKYGIVLDAGSSRTTVYVYQWPAEKENNTGVVSQTFRCSVKGSGISSYENNPQDAPKAFEDCMLKVKEQVPKHLHESTRVYLGATAGMRLLRLQNETAAHEVLESIQSYFKSQPFDFRGAQIISGQEEGVYGWITANYIMGNFLEKNLWHMWVHPHGVDTTGALDLGGASTQISFVSEEKMEPNASDTVQVSLYGYTYTLYTHSFQCYGRNEAEKKFLAMLLQSPSTDANISNPCYPHGYSTTFTMGHVFGSLCTEKQRPKSYNPSDTITFTGTGDPQLCREKVASVFDFSACQEQDACSFDGIYQPKVQGPFVAFAGFYYTASALNLSGSFSLTSFNDSSWDFCRHTWSELPSLLPRFDETYARSYCFSAHYIYHLLINGYKFTEATWPQIRFEKEVGNSSIAWSLGYMLSLTNQIPAGSPLIQLPIQPPVFMGVLAFFTAIALLCLAFLFYLCSAFRTKERSENAFDQAVDSD\n",
      ">Q9NVV2|CS073_HUMAN MRLKVGFQGGGCFRKDALCLEGGVSARWARAPHSAPLRPPRELHAAPPPATPTQTVVRPAGFPRRTRLMVRSAPPTQRPPTGSGCVSGLWRKGLGLRPQTLLRVGSVVLSSAPALRPRLGPCLRPPPSD\n",
      ">O00628|PEX7_HUMAN MSAVCGGAARMLRTPGRHGYAAEFSPYLPGRLACATAQHYGIAGCGTLLILDPDEAGLRLFRSFDWNDGLFDVTWSENNEHVLITCSGDGSLQLWDTAKAAGPLQVYKEHAQEVYSVDWSQTRGEQLVVSGSWDQTVKLWDPTVGKSLCTFRGHESIIYSTIWSPHIPGCFASASGDQTLRIWDVKAAGVRIVIPAHQAEILSCDWCKYNENLLVTGAVDCSLRGWDLRNVRQPVFELLGHTYAIRRVKFSPFHASVLASCSYDFTVRFWNFSKPDSLLETVEHHTEFTCGLDFSLQSPTQVADCSWDETIKIYDPACLTIPA\n",
      ">A0A8M9P7W8|A0A8M9P7W8_DANRE MKLPSVASLLIRVYRTTGPVSHIQRIRHGAVLNKNYSSVSAVKNCTALLYRNHGEPSQVVQLESLDLPQVGAECVLVKMLAAPINPSDLNMLQGTYAILPELPAVGGNEGVAQVMEVGDKVKTLKVGDWVIPKDAGIGTWRTAAVLKADDLVTLPKDIPVLSAATLGVNPCTAYRMLTDFEELKAGRQCS\n",
      ">A0A5G2R2Q0|A0A5G2R2Q0_PIG MYVDSLYIQHTILCKLIALYWEEKTDSKKVEENIKTDEPSSEESDLEIDNEGVIEPDTDAPQEMGDENVEITEEMMDQANDKKVAAIDALNNGELQKAIDLFTDAIKLNPRLAILYAKRASVFIKLQKPNAAIRDCDRAIEINPDSAQPYKWRGKAHRLLGHWEEAAHDLALACKLDYDEDASAMLKEVQPRAQKIAEHRRKYERKREEREIKERIERVKKAREEHERAQREEEARRQSGAQYGSFPGGFPGGMPGNFPGGMPGMGGSMPGMAGMPGLNEILSDPEVLAAMQDPEVMVAFQDVAQNPANMSKYQSNPKVMNLISKLSAKFGGQA\n",
      "Skipping 3 elements.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from utils import load_csv_dataset\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "save_file = Path('./test.pkl')\n",
    "\n",
    "# Dataset\n",
    "n_proteins = 1_000_000\n",
    "\n",
    "dataset = \"UniProt\"\n",
    "\n",
    "if dataset == \"CASP\":\n",
    "    data_name = \"CASP14\"\n",
    "    data_path = \"casp14.pickle\"\n",
    "    max_length = 2048 # AMPLIFY was trained with a context length of 512\n",
    "\n",
    "    # Load dataset\n",
    "    labels, proteins, dist_matrices = load_pickle_dataset(data_path, n_proteins, max_length)\n",
    "    full_dataset = list(zip(labels, proteins))\n",
    "    \n",
    "    for (label, protein) in itertools.islice(full_dataset, 0, 5):\n",
    "        print(label, protein)\n",
    "    \n",
    "else:\n",
    "    # Dataset\n",
    "    data_name = \"UniProt\"\n",
    "    data_path = \"uniprot_dev.csv\"\n",
    "    \n",
    "    # Prepare the dataset\n",
    "    full_dataset = load_csv_dataset(data_path, n_proteins)\n",
    "    \n",
    "    for (label, protein) in itertools.islice(full_dataset, 0, 5):\n",
    "        print(label, protein)\n",
    "\n",
    "count = 0\n",
    "num_passes = 5\n",
    "\n",
    "if os.path.exists(save_file):\n",
    "    file = open(save_file, 'rb')\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            data = pickle.load(file)\n",
    "            count += 1\n",
    "        except EOFError:\n",
    "            break\n",
    "\n",
    "print(f\"Skipping {count} elements.\")\n",
    "\n",
    "repeated_dataset = get_dataset(full_dataset, num_passes)\n",
    "sliced_dataset = itertools.islice(repeated_dataset, count, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "4d8b538d-74b6-46aa-820a-fde24c6d93e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[222], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcompute_attributions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproteins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msliced_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_length\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/main_envs/amplify_env/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[219], line 144\u001b[0m, in \u001b[0;36mcompute_attributions\u001b[0;34m(model, tokenizer, proteins, device, save_file, chunk_size, mask_probability, span_probability, span_max, masked_only, exclude_special_tokens_replacement, fp16, max_length)\u001b[0m\n\u001b[1;32m    141\u001b[0m original_logits \u001b[38;5;241m=\u001b[39m reference_output[\u001b[38;5;241m0\u001b[39m][mask_indices[target_index]]\n\u001b[1;32m    142\u001b[0m new_logits \u001b[38;5;241m=\u001b[39m test_output[modified_index][mask_indices[target_index]]\n\u001b[0;32m--> 144\u001b[0m absolute_difference \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_logits\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnew_logits\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    146\u001b[0m log_softmax_reference \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mlog_softmax(original_logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    147\u001b[0m softmax_targets \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(new_logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "compute_attributions(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    proteins=sliced_dataset,\n",
    "    device=device,\n",
    "    save_file=save_file,\n",
    "    max_length=model.config.max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "113d7041-b092-4fe9-9d20-e399a92dc61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 434714\n",
      "drwxr-x---+  4 jerry.huang jerry.huang        19 Nov 26 17:25 .\n",
      "drwxr-x---+ 11 jerry.huang jerry.huang        13 Oct 21 13:51 ..\n",
      "-rw-r-----+  1 jerry.huang jerry.huang      2274 Sep 30 14:50 AMPLIFY_350_config.yaml\n",
      "-rw-r-----+  1 jerry.huang jerry.huang   3423722 Nov 18 20:45 attribution.ipynb\n",
      "-rw-r-----+  1 jerry.huang jerry.huang 410266502 Sep 25 14:18 casp14.pickle\n",
      "-rw-r-----+  1 jerry.huang jerry.huang     16244 Nov 26 17:23 compute_masked_influence.py\n",
      "-rw-r-----+  1 jerry.huang jerry.huang    253731 Sep 30 14:14 contact_prediction.ipynb\n",
      "-rw-r-----+  1 jerry.huang jerry.huang      5362 Sep 30 14:14 efficiency.ipynb\n",
      "-rw-r-----+  1 jerry.huang jerry.huang  10835636 Nov  8 13:56 feature_ablation.ipynb\n",
      "drwxr-x---+  2 jerry.huang jerry.huang         8 Nov 26 15:10 .ipynb_checkpoints\n",
      "-rw-r-----+  1 jerry.huang jerry.huang     77305 Nov 26 17:25 masked_influence.ipynb\n",
      "-rw-r-----+  1 jerry.huang jerry.huang     23049 Sep 30 14:14 projection_proteins.ipynb\n",
      "-rw-r-----+  1 jerry.huang jerry.huang     19963 Sep 30 14:14 projection_residues.ipynb\n",
      "-rw-r-----+  1 jerry.huang jerry.huang     35080 Nov 18 19:27 pseudo_ppl.ipynb\n",
      "drwxr-x---+  2 jerry.huang jerry.huang         1 Sep 30 14:46 __pycache__\n",
      "-rw-r-----+  1 jerry.huang jerry.huang    164810 Nov 26 17:26 test.pkl\n",
      "-rw-r-----+  1 jerry.huang jerry.huang   5582053 Oct 21 13:57 uniprot_dev.csv\n",
      "-rw-r--r--+  1 jerry.huang jerry.huang   5582039 Sep 23 16:18 uniprot_dev.fasta\n",
      "-rw-r-----+  1 jerry.huang jerry.huang   3267270 Oct 21 13:56 uniprot_dev.fasta.zip\n",
      "-rw-r-----+  1 jerry.huang jerry.huang   5582039 Sep 25 14:18 uniprot.fasta\n",
      "-rw-r-----+  1 jerry.huang jerry.huang      3641 Sep 30 14:14 utils.py\n"
     ]
    }
   ],
   "source": [
    "! ls -l -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "6d295d6d-9b26-4f67-8aa1-6ff87fc8032d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">A0A8M9P7W8|A0A8M9P7W8_DANRE\n",
      ">A0A5G2R2Q0|A0A5G2R2Q0_PIG\n",
      ">Q5SIM6|Q5SIM6_THET8\n",
      "3\n",
      ">A0A8M9P7W8|A0A8M9P7W8_DANRE\n",
      ">A0A5G2R2Q0|A0A5G2R2Q0_PIG\n",
      ">Q5SIM6|Q5SIM6_THET8\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "if os.path.exists(save_file):\n",
    "    file = open(save_file, 'rb')\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            data = pickle.load(file)\n",
    "            print(data['label'])\n",
    "            count += 1\n",
    "        except EOFError:\n",
    "            break\n",
    "\n",
    "    file.close()\n",
    "\n",
    "print(count)\n",
    "\n",
    "count = 0\n",
    "\n",
    "if os.path.exists(save_file):\n",
    "    file = open(save_file, 'rb')\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            data = pickle.load(file)\n",
    "            print(data['label'])\n",
    "            count += 1\n",
    "            # print(data)\n",
    "        except EOFError:\n",
    "            break\n",
    "\n",
    "    file.close()\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "52ac69a2-9466-4dea-a232-4518601264c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8626fca-83cb-42a0-962a-645068e4b6fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
